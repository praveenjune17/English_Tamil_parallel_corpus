{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Train_eng_tam_NMT.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/praveenjune17/English_Tamil_parallel_corpus/blob/master/Train_eng_tam_NMT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IG1GpEuwOZr5",
        "colab_type": "text"
      },
      "source": [
        "**a)**  Please refer  https://www.tensorflow.org/beta/tutorials/text/transformer#create_the_transformer to gain indepth knowledge about transformers .\n",
        "\n",
        "**b)**     Change runtime to GPU before running this script"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80s7bpmq8BFX",
        "colab_type": "code",
        "outputId": "2a9a8f9a-9f8f-4db8-d97d-caaa87429840",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        }
      },
      "source": [
        "!pip install tensorflow-gpu==2.0.0-beta1\n",
        "\n",
        "# Upgrade the beam_search script to TF2 in tensor2tensor since the exsisting is not compatible with TF2\n",
        "!tf_upgrade_v2 \\\n",
        "  --infile /usr/local/lib/python3.6/dist-packages/tensor2tensor/utils/beam_search.py \\\n",
        "  --outfile /usr/local/lib/python3.6/dist-packages/tensor2tensor/utils/beam_search.py\n",
        "\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "from tensor2tensor.utils.beam_search import beam_search\n",
        "from collections import defaultdict\n",
        "import os\n",
        "import shutil"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow-gpu==2.0.0-beta1 in /usr/local/lib/python3.6/dist-packages (2.0.0b1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.11.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.1.0)\n",
            "Requirement already satisfied: tb-nightly<1.14.0a20190604,>=1.14.0a20190603 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.14.0a20190603)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.16.4)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (0.7.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (3.7.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (0.33.4)\n",
            "Requirement already satisfied: tf-estimator-nightly<1.14.0.dev2019060502,>=1.14.0.dev2019060501 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.14.0.dev2019060501)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (0.1.7)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (0.2.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (0.8.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==2.0.0-beta1) (2.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow-gpu==2.0.0-beta1) (3.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow-gpu==2.0.0-beta1) (0.15.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow-gpu==2.0.0-beta1) (41.0.1)\n",
            "TensorFlow 2.0 Upgrade Script\n",
            "-----------------------------\n",
            "Converted 1 files\n",
            "Detected 0 issues that require attention\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "Make sure to read the detailed log 'report.txt'\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzZHIEbQFWxG",
        "colab_type": "text"
      },
      "source": [
        "### Patch script to add eng-tam parallel corpus into tensorflow datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VLj2C9Fgk_c",
        "colab_type": "code",
        "outputId": "70ec8552-05b2-438c-d908-f4b4f4845cca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "if not os.path.exists('Neural-Machine-Translation-English-Tamil-model'):\n",
        "  !git clone https://github.com/praveenjune17/Neural-Machine-Translation-English-Tamil-model\n",
        "  !unzip Neural-Machine-Translation-English-Tamil-model/tfds_patch_scripts/Transformer_en_tam_2.zip\n",
        "  \n",
        "#set the path to the where tfds is installed\n",
        "path = '/usr/local/lib/python3.6/dist-packages/tensorflow_datasets'\n",
        "shutil.copy('../content/Transformer_en_tam_2/__init__.py', os.path.join(path, 'translate/__init__.py'))\n",
        "shutil.copy('../content/Transformer_en_tam_2/en_tam_parallel_text.py', os.path.join(path, 'translate/en_tam_parallel_text.py'))\n",
        "shutil.copy('../content/Transformer_en_tam_2/en_tam_parallel_text_test.py', os.path.join(path, 'translate/en_tam_parallel_text_test.py'))\n",
        "shutil.copy('../content/Transformer_en_tam_2/en_tam_parallel_text.txt', os.path.join(path, 'url_checksums/en_tam_parallel_text.txt'))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/usr/local/lib/python3.6/dist-packages/tensorflow_datasets/url_checksums/en_tam_parallel_text.txt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rmi5aqfMnptL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import tfds only after the patch is copied.\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(100)\n",
        "\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qe9DsFVFGCqS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "2c0f3137-db94-4e1c-cafb-c43eba6875ff"
      },
      "source": [
        "# using a single sample(github_joshua_en_ta) for training \n",
        "# this dataset contains 110K lines of en, ta parallel text\n",
        "examples, meta_data  = tfds.load('en_tam_parallel_text/github_joshua_en_ta', with_info=True, as_supervised=True)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0812 05:26:28.902003 140573774956416 dataset_builder.py:439] Warning: Setting shuffle_files=True because split=TRAIN and shuffle_files=None. This behavior will be deprecated on 2019-08-06, at which point shuffle_files=False will be the default for all splits.\n",
            "W0812 05:26:28.934224 140573774956416 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/data/util/random_seed.py:58: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erlMhNlDIPkH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "# Drop examples of token size greater than 50 \n",
        "MAX_LENGTH = 50                                                 \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EerFbcuKAz5s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Subword generation API # Took 180secs to complete in the last run\n",
        "\n",
        "train_examples = examples['train']\n",
        "tokenizer_en = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n",
        "  (en.numpy() for  en, _ in train_examples), target_vocab_size=2**13)\n",
        "tokenizer_ta = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n",
        "  (ta.numpy() for _, ta in train_examples), target_vocab_size=2**13)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCrEFIOaEkEM",
        "colab_type": "code",
        "outputId": "cafc89dd-0a6f-433e-84f2-3cbdcf0eb594",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "sample_string = 'Transformer is awesome.'\n",
        "\n",
        "tokenized_string_eng = tokenizer_en.encode(sample_string)\n",
        "print ('Tokenized string is {}'.format(tokenized_string_eng))\n",
        "\n",
        "original_string = tokenizer_en.decode(tokenized_string_eng)\n",
        "print ('The original string: {}'.format(original_string))\n",
        "\n",
        "assert original_string == sample_string"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tokenized string is [8123, 1227, 5516, 297, 2308, 8071, 8, 7984, 94, 3439, 8085]\n",
            "The original string: Transformer is awesome.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDYMvh9hEslb",
        "colab_type": "code",
        "outputId": "7ad442d3-1b26-43eb-ddaf-e093c3530520",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "sample_string = 'நீங்கள் இங்கு அரட்டை அடிக்க அனுமதி இல்லை'\n",
        "tokenized_string_ta = tokenizer_ta.encode(sample_string)\n",
        "print ('Tokenized string is {}'.format(tokenized_string_ta))\n",
        "\n",
        "original_string = tokenizer_ta.decode(tokenized_string_ta)\n",
        "print ('The original string: {}'.format(original_string))\n",
        "assert original_string == sample_string"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tokenized string is [21, 32, 52, 1, 19, 4, 258, 1, 5, 20, 174, 11, 1, 11, 24, 84, 2, 5, 1, 33, 109, 3, 104, 29, 133, 1, 12, 10]\n",
            "The original string: நீங்கள் இங்கு அரட்டை அடிக்க அனுமதி இல்லை\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKfs3TWDEu2e",
        "colab_type": "code",
        "outputId": "70a6cb70-d3c7-4526-b77f-c3d6d02554fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        }
      },
      "source": [
        "for ts in tokenized_string_eng:\n",
        "  print ('{} ----> {}'.format(ts, tokenizer_en.decode([ts])))\n",
        "for ts in tokenized_string_ta:\n",
        "  print ('{} ----> {}'.format(ts, tokenizer_ta.decode([ts])))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8123 ----> T\n",
            "1227 ----> ran\n",
            "5516 ----> sf\n",
            "297 ----> or\n",
            "2308 ----> mer\n",
            "8071 ---->  \n",
            "8 ----> is \n",
            "7984 ----> aw\n",
            "94 ----> es\n",
            "3439 ----> ome\n",
            "8085 ----> .\n",
            "21 ----> ந\n",
            "32 ----> ீ\n",
            "52 ----> ங\n",
            "1 ----> ்\n",
            "19 ----> கள\n",
            "4 ----> ் \n",
            "258 ----> இங\n",
            "1 ----> ்\n",
            "5 ----> க\n",
            "20 ----> ு \n",
            "174 ----> அர\n",
            "11 ----> ட\n",
            "1 ----> ்\n",
            "11 ----> ட\n",
            "24 ----> ை \n",
            "84 ----> அட\n",
            "2 ----> ி\n",
            "5 ----> க\n",
            "1 ----> ்\n",
            "33 ----> க \n",
            "109 ----> அன\n",
            "3 ----> ு\n",
            "104 ----> மத\n",
            "29 ----> ி \n",
            "133 ----> இல\n",
            "1 ----> ்\n",
            "12 ----> ல\n",
            "10 ----> ை\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gt5kGKQOGQyA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encode(lang1, lang2):\n",
        "  lang1 = [tokenizer_en.vocab_size] + tokenizer_en.encode(\n",
        "      lang1.numpy()) + [tokenizer_en.vocab_size+1]\n",
        "\n",
        "  lang2 = [tokenizer_ta.vocab_size] + tokenizer_ta.encode(\n",
        "      lang2.numpy()) + [tokenizer_ta.vocab_size+1]\n",
        "  \n",
        "  return lang1, lang2\n",
        "\n",
        "def filter_max_length(x, y, max_length=MAX_LENGTH):\n",
        "  \n",
        "  return tf.logical_and(tf.size(x) <= max_length,\n",
        "                        tf.size(y) <= max_length)\n",
        "\n",
        "def tf_encode(en, ta):\n",
        "  return tf.py_function(encode, [en, ta], [tf.int64, tf.int64])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPEJXyS3EbWk",
        "colab_type": "code",
        "outputId": "f09355b5-73c6-43d0-cfff-002ad3159950",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train_dataset = train_examples.map(tf_encode)\n",
        "train_dataset = train_dataset.filter(filter_max_length)\n",
        "BUFFER_SIZE = 160000\n",
        "train_dataset = train_dataset.cache()\n",
        "train_dataset = train_dataset.shuffle(BUFFER_SIZE, seed=100).padded_batch(\n",
        "    BATCH_SIZE, padded_shapes=([-1], [-1]))\n",
        "train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "en_batch, ta_batch = next(iter(train_dataset))\n",
        "en_batch, ta_batch"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0812 05:29:13.175656 140571801765632 backprop.py:842] The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.string\n",
            "W0812 05:29:13.177540 140571801765632 backprop.py:842] The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.string\n",
            "W0812 05:29:13.179733 140571818551040 backprop.py:842] The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.string\n",
            "W0812 05:29:13.180990 140571818551040 backprop.py:842] The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.string\n",
            "W0812 05:29:13.192764 140571818551040 backprop.py:842] The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.string\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: id=1428288, shape=(64, 13), dtype=int64, numpy=\n",
              " array([[8295, 2745,   81, 8296,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0],\n",
              "        [8295, 1247, 8296,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0],\n",
              "        [8295, 7783, 3357, 1050, 8296,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0],\n",
              "        [8295, 4905, 5910, 1548, 8136, 8296,    0,    0,    0,    0,    0,\n",
              "            0,    0],\n",
              "        [8295, 5245,   52, 6608, 8296,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0],\n",
              "        [8295, 2161, 1385, 8296,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0],\n",
              "        [8295, 2485, 8296,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0],\n",
              "        [8295, 7259,  804, 8296,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0],\n",
              "        [8295, 5183, 3848, 8154, 8296,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0],\n",
              "        [8295, 6696,  120, 1634, 8296,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0],\n",
              "        [8295,    2,  193,  144, 8296,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0],\n",
              "        [8295, 4612, 1056, 8156, 8296,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0],\n",
              "        [8295, 1414, 8154, 8296,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0],\n",
              "        [8295, 1787, 8154, 8296,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0],\n",
              "        [8295, 4518,  355, 1733, 1080, 8296,    0,    0,    0,    0,    0,\n",
              "            0,    0],\n",
              "        [8295,   21, 1073, 8296,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0],\n",
              "        [8295, 1013, 8078,    7,   51, 4649, 8071, 3031, 4412, 1961, 2701,\n",
              "         8160, 8296],\n",
              "        [8295, 2225, 2888, 1384, 3573,  626,   32,  653,    6, 5431, 3840,\n",
              "         8296,    0],\n",
              "        [8295, 6482,  721, 8296,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0],\n",
              "        [8295,  234,   27,    9,  531, 2967, 1520, 8296,    0,    0,    0,\n",
              "            0,    0],\n",
              "        [8295, 6577, 8296,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0],\n",
              "        [8295, 7281,  292, 4056, 8071,   11, 3001, 4517, 8296,    0,    0,\n",
              "            0,    0],\n",
              "        [8295, 1323, 8296,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0],\n",
              "        [8295,   30,  648, 8296,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0],\n",
              "        [8295, 7781,   61, 4655,    9, 7781, 8148, 8296,    0,    0,    0,\n",
              "            0,    0],\n",
              "        [8295,  309, 5526, 2789,  126,  133, 8296,    0,    0,    0,    0,\n",
              "            0,    0],\n",
              "        [8295, 2376,  605, 2779, 8296,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0],\n",
              "        [8295, 6486,  231, 8296,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0],\n",
              "        [8295,  234,   27,  485, 1520, 8296,    0,    0,    0,    0,    0,\n",
              "            0,    0],\n",
              "        [8295,    6, 2621, 8296,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0],\n",
              "        [8295,  871, 8296,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0],\n",
              "        [8295, 6813, 8296,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0],\n",
              "        [8295, 1231, 8154, 8296,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0],\n",
              "        [8295, 2334, 8296,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0],\n",
              "        [8295, 6864, 8154, 8296,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0],\n",
              "        [8295, 1446, 8093, 8296,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0],\n",
              "        [8295, 5437, 8296,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0],\n",
              "        [8295,   71, 8296,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0],\n",
              "        [8295,   71, 8296,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0],\n",
              "        [8295, 2373, 6271, 1102, 2668,   42, 1697, 4296,  358, 8296,    0,\n",
              "            0,    0],\n",
              "        [8295, 4741,  523,  472, 8296,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0],\n",
              "        [8295,  144, 8296,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0],\n",
              "        [8295,  569, 8296,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0],\n",
              "        [8295, 1884, 1177,    2,  775, 8296,    0,    0,    0,    0,    0,\n",
              "            0,    0],\n",
              "        [8295,   86,    8,    9, 6579,  381, 1391, 6751, 8138, 8296,    0,\n",
              "            0,    0],\n",
              "        [8295, 2291, 8296,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0],\n",
              "        [8295, 7478, 8296,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0],\n",
              "        [8295, 2415,  149, 1189, 8296,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0],\n",
              "        [8295,  396, 1236,  430,   14, 6684, 4757, 8296,    0,    0,    0,\n",
              "            0,    0],\n",
              "        [8295, 7996, 8156, 8296,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0],\n",
              "        [8295, 2944, 8154, 8296,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0],\n",
              "        [8295, 1095,  751, 8296,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0],\n",
              "        [8295,  374,  568,  329, 8078,    7,  306, 1128, 8296,    0,    0,\n",
              "            0,    0],\n",
              "        [8295, 2505, 8296,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0],\n",
              "        [8295, 4667, 6947,  472, 8296,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0],\n",
              "        [8295,  998,  837, 1658, 8154, 8296,    0,    0,    0,    0,    0,\n",
              "            0,    0],\n",
              "        [8295, 6991,   47,    8,    9, 5995,  192, 8296,    0,    0,    0,\n",
              "            0,    0],\n",
              "        [8295, 6003, 8296,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0],\n",
              "        [8295,  131, 2215, 8296,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0],\n",
              "        [8295, 7541, 8296,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0],\n",
              "        [8295,  176, 4231, 8154, 8296,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0],\n",
              "        [8295, 3513,  730, 2745, 8296,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0],\n",
              "        [8295,  319,  924, 8296,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0],\n",
              "        [8295, 1314, 3068, 2830, 8296,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0]])>,\n",
              " <tf.Tensor: id=1428289, shape=(64, 49), dtype=int64, numpy=\n",
              " array([[4701,  232,    1, ...,    0,    0,    0],\n",
              "        [4701,   14,    2, ...,    0,    0,    0],\n",
              "        [4701,    8,   23, ...,    0,    0,    0],\n",
              "        ...,\n",
              "        [4701,  397,    2, ...,    0,    0,    0],\n",
              "        [4701,  486,    6, ...,    0,    0,    0],\n",
              "        [4701, 1404,    1, ...,    0,    0,    0]])>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjP_RgKrG6-J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_angles(pos, i, d_model):\n",
        "  angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
        "  return pos * angle_rates\n",
        "def positional_encoding(position, d_model):\n",
        "  angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
        "                          np.arange(d_model)[np.newaxis, :],\n",
        "                          d_model)\n",
        "  \n",
        "  # apply sin to even indices in the array; 2i\n",
        "  sines = np.sin(angle_rads[:, 0::2])\n",
        "  \n",
        "  # apply cos to odd indices in the array; 2i+1\n",
        "  cosines = np.cos(angle_rads[:, 1::2])\n",
        "  \n",
        "  pos_encoding = np.concatenate([sines, cosines], axis=-1)\n",
        "  \n",
        "  pos_encoding = pos_encoding[np.newaxis, ...]\n",
        "    \n",
        "  return tf.cast(pos_encoding, dtype=tf.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WQs-C1vG_HK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_padding_mask(seq):\n",
        "  seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
        "  \n",
        "  # add extra dimensions so that we can add the padding\n",
        "  # to the attention logits.\n",
        "  return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YW97479YHBtP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_look_ahead_mask(size):\n",
        "  mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)  #(1 - lower_triangular_matrix)\n",
        "  return mask  # (seq_len, seq_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WaVGCsgHDdm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def scaled_dot_product_attention(q, k, v, mask):\n",
        "  \"\"\"Calculate the attention weights.\n",
        "  q, k, v must have matching leading dimensions.\n",
        "  k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
        "  The mask has different shapes depending on its type(padding or look ahead) \n",
        "  but it must be broadcastable for addition.\n",
        "  \n",
        "  Args:\n",
        "    q: query shape == (..., seq_len_q, depth)\n",
        "    k: key shape == (..., seq_len_k, depth)\n",
        "    v: value shape == (..., seq_len_v, depth_v)\n",
        "    mask: Float tensor with shape broadcastable \n",
        "          to (..., seq_len_q, seq_len_k). Defaults to None.\n",
        "    \n",
        "  Returns:\n",
        "    output, attention_weights\n",
        "  \"\"\"\n",
        "\n",
        "  matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
        "  \n",
        "  # scale matmul_qk\n",
        "  dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
        "  scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
        "\n",
        "  # add the mask to the scaled tensor.\n",
        "  if mask is not None:\n",
        "    scaled_attention_logits += (mask * -1e9)  \n",
        "\n",
        "  # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
        "  # add up to 1.\n",
        "  attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
        "\n",
        "  output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
        "\n",
        "  return output, attention_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOXpFdSkHFco",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads):\n",
        "    super(MultiHeadAttention, self).__init__()\n",
        "    self.num_heads = num_heads\n",
        "    self.d_model = d_model\n",
        "    \n",
        "    assert d_model % self.num_heads == 0\n",
        "    \n",
        "    self.depth = d_model // self.num_heads\n",
        "    \n",
        "    self.wq = tf.keras.layers.Dense(d_model)\n",
        "    self.wk = tf.keras.layers.Dense(d_model)\n",
        "    self.wv = tf.keras.layers.Dense(d_model)\n",
        "    \n",
        "    self.dense = tf.keras.layers.Dense(d_model)\n",
        "        \n",
        "  def split_heads(self, x, batch_size):\n",
        "    \"\"\"Split the last dimension into (num_heads, depth).\n",
        "    Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
        "    \"\"\"\n",
        "    x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
        "    return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "    \n",
        "  def call(self, v, k, q, mask):\n",
        "    batch_size = tf.shape(q)[0]\n",
        "    \n",
        "    q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
        "    k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
        "    v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
        "    \n",
        "    q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
        "    k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
        "    v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
        "    \n",
        "    # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
        "    # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
        "    scaled_attention, attention_weights = scaled_dot_product_attention(\n",
        "        q, k, v, mask)\n",
        "    \n",
        "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
        "\n",
        "    concat_attention = tf.reshape(scaled_attention, \n",
        "                                  (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "    output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
        "        \n",
        "    return output, attention_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0gXPOekHJMv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def point_wise_feed_forward_network(d_model, dff):\n",
        "  return tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
        "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
        "  ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7K719wF8HLtJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "    super(EncoderLayer, self).__init__()\n",
        "\n",
        "    self.mha = MultiHeadAttention(d_model, num_heads)\n",
        "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    \n",
        "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "    \n",
        "  def call(self, x, training, mask):\n",
        "\n",
        "    attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
        "    attn_output = self.dropout1(attn_output, training=training)\n",
        "    out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
        "    \n",
        "    ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
        "    ffn_output = self.dropout2(ffn_output, training=training)\n",
        "    out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
        "    \n",
        "    return out2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuVKWQUrHNY1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "    super(DecoderLayer, self).__init__()\n",
        "\n",
        "    self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
        "    self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
        "\n",
        "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        " \n",
        "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    \n",
        "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout3 = tf.keras.layers.Dropout(rate)\n",
        "    \n",
        "    \n",
        "  def call(self, x, enc_output, training, \n",
        "           look_ahead_mask, padding_mask):\n",
        "    # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
        "\n",
        "    attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
        "    attn1 = self.dropout1(attn1, training=training)\n",
        "    out1 = self.layernorm1(attn1 + x)\n",
        "    \n",
        "    attn2, attn_weights_block2 = self.mha2(\n",
        "        enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
        "    attn2 = self.dropout2(attn2, training=training)\n",
        "    out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
        "    \n",
        "    ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
        "    ffn_output = self.dropout3(ffn_output, training=training)\n",
        "    out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
        "    \n",
        "    return out3, attn_weights_block1, attn_weights_block2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkaiGKw5HPao",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, \n",
        "               rate=0.1):\n",
        "    super(Encoder, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "    \n",
        "    self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
        "    self.pos_encoding = positional_encoding(input_vocab_size, self.d_model)\n",
        "    \n",
        "    \n",
        "    self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) \n",
        "                       for _ in range(num_layers)]\n",
        "  \n",
        "    self.dropout = tf.keras.layers.Dropout(rate)\n",
        "        \n",
        "  def call(self, x, training, mask):\n",
        "\n",
        "    seq_len = tf.shape(x)[1]\n",
        "    \n",
        "    # adding embedding and position encoding.\n",
        "    x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
        "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))  #(refer last line of 3.4 Embeddings and Softmax)\n",
        "    x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "    x = self.dropout(x, training=training)\n",
        "    \n",
        "    for i in range(self.num_layers):\n",
        "      x = self.enc_layers[i](x, training, mask)\n",
        "    \n",
        "    return x  # (batch_size, input_seq_len, d_model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84XmYPleHRHY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size, \n",
        "               rate=0.1):\n",
        "    super(Decoder, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "    \n",
        "    self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
        "    self.pos_encoding = positional_encoding(target_vocab_size, self.d_model)\n",
        "    \n",
        "    self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) \n",
        "                       for _ in range(num_layers)]\n",
        "    self.dropout = tf.keras.layers.Dropout(rate)\n",
        "    \n",
        "  def call(self, x, enc_output, training, \n",
        "           look_ahead_mask, padding_mask):\n",
        "\n",
        "    seq_len = tf.shape(x)[1]\n",
        "    attention_weights = {}\n",
        "    \n",
        "    x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
        "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "    x += self.pos_encoding[:, :seq_len, :]\n",
        "    \n",
        "    x = self.dropout(x, training=training)\n",
        "\n",
        "    for i in range(self.num_layers):\n",
        "      x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
        "                                             look_ahead_mask, padding_mask)\n",
        "      \n",
        "      attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
        "      attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
        "    \n",
        "    # x.shape == (batch_size, target_seq_len, d_model)\n",
        "    return x, attention_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7yCVU54HStK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Transformer(tf.keras.Model):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, \n",
        "               target_vocab_size, rate=0.1):\n",
        "    super(Transformer, self).__init__()\n",
        "\n",
        "    self.encoder = Encoder(num_layers, d_model, num_heads, dff, \n",
        "                           input_vocab_size, rate)\n",
        "\n",
        "    self.decoder = Decoder(num_layers, d_model, num_heads, dff, \n",
        "                           target_vocab_size, rate)\n",
        "\n",
        "    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
        "    \n",
        "  def call(self, inp, tar, training, enc_padding_mask, \n",
        "           look_ahead_mask, dec_padding_mask):\n",
        "\n",
        "    enc_output = self.encoder(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
        "    \n",
        "    # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
        "    dec_output, attention_weights = self.decoder(\n",
        "        tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
        "    \n",
        "    final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
        "    \n",
        "    return final_output, attention_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfA94kvaHUZy",
        "colab_type": "code",
        "outputId": "aa18603d-153c-4e58-bbd9-555af489d802",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "num_layers = 4  #denoted as 'L' in BERT , no.of blocks\n",
        "d_model = 256   #ll sub-layers in the model, as well as the embedding layers, produce outputs of dimension dmodel=512.\n",
        "dff = 1024      #denoted as 'H' in BERT \n",
        "num_heads = 4   #denoted as 'A' in BERT\n",
        "input_vocab_size = tokenizer_en.vocab_size + 2\n",
        "target_vocab_size = tokenizer_ta.vocab_size + 2\n",
        "dropout_rate = 0.3\n",
        "print('english vocab size is {} '.format(input_vocab_size))\n",
        "print('tamil vocab size is {}'.format(target_vocab_size))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "english vocab size is 8297 \n",
            "tamil vocab size is 4703\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNAXknWsHWxi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super(CustomSchedule, self).__init__()\n",
        "    \n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "    self.warmup_steps = warmup_steps\n",
        "    \n",
        "  def __call__(self, step):\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps ** -1.5)\n",
        "    \n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHEdCcJ4IF8W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate = CustomSchedule(d_model)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate, beta_1=0.9, beta_2=0.98, \n",
        "                                     epsilon=1e-9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgpnyROuIHU9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYLI7xkQIM3H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "  \n",
        "  return tf.reduce_mean(loss_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "easgYyRIIO0R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
        "    name='train_accuracy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcUnvi0nIQ7I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transformer = Transformer(num_layers, d_model, num_heads, dff,\n",
        "                          input_vocab_size, target_vocab_size, dropout_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taC9AGxmISwL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_masks(inp, tar):\n",
        "  # Encoder padding mask\n",
        "  enc_padding_mask = create_padding_mask(inp)  #output 1 if padded 0 is present else 0\n",
        "  \n",
        "  # Used in the 2nd attention block in the decoder.\n",
        "  # This padding mask is used to mask the encoder outputs.\n",
        "  dec_padding_mask = create_padding_mask(inp)\n",
        "  # Used in the 1st attention block in the decoder.\n",
        "  # It is used to pad and mask future tokens in the input received by \n",
        "  # the decoder.allows decoder to attend to all positions in the decoder up to and including that position(refer architecture)\n",
        "  dec_target_padding_mask = create_padding_mask(tar)\n",
        "  \n",
        "  look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
        "  \n",
        "  combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
        "  \n",
        "  return enc_padding_mask, combined_mask, dec_padding_mask"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GyK6bV8bIVnm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint_path = './Checkpoints/Train_from_scratch'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nJRAqU9IYD3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ckpt = tf.train.Checkpoint(transformer=transformer,\n",
        "                           optimizer=optimizer)\n",
        "\n",
        "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
        "\n",
        "# if a checkpoint exists, restore the latest checkpoint.\n",
        "if (ckpt_manager.latest_checkpoint):\n",
        "  ckpt.restore(ckpt_manager.latest_checkpoint).expect_partial()\n",
        "  print ('Latest checkpoint restored is {} !!'.format(ckpt_manager.latest_checkpoint.split('/')[-1]))\n",
        "  print ('size of the checkpoint directory is {}MB '.format(sum(os.path.getsize(os.path.join(checkpoint_path,f)) for f in os.listdir(checkpoint_path))/(1024*1024)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycgmHwc6Ia8-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3x6snSRIezM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The @tf.function trace-compiles train_step into a TF graph for faster\n",
        "# execution. The function specializes to the precise shape of the argument\n",
        "# tensors. To avoid re-tracing due to the variable sequence lengths or variable\n",
        "# batch sizes (the last batch is smaller), use input_signature to specify\n",
        "# more generic shapes.\n",
        "\n",
        "train_step_signature = [\n",
        "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
        "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
        "]\n",
        "\n",
        "@tf.function(input_signature=train_step_signature)\n",
        "def train_step(inp, tar):\n",
        "  tar_inp = tar[:, :-1]\n",
        "  tar_real = tar[:, 1:]\n",
        "  \n",
        "  enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
        "  \n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions, _ = transformer(inp, tar_inp, \n",
        "                                 True, \n",
        "                                 enc_padding_mask, \n",
        "                                 combined_mask, \n",
        "                                 dec_padding_mask)\n",
        "    loss = loss_function(tar_real, predictions)\n",
        "    \n",
        "  gradients = tape.gradient(loss, transformer.trainable_variables)    \n",
        "  optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
        "  \n",
        "  train_loss(loss)\n",
        "  train_accuracy(tar_real, predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYqMwiMkIifi",
        "colab_type": "code",
        "outputId": "a00db2ad-1571-402c-f66d-a7d9d0b6eee3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for epoch in range(EPOCHS): #train for 4 hours\n",
        "  \n",
        "  start = time.time()  \n",
        "  train_loss.reset_states()\n",
        "  train_accuracy.reset_states()\n",
        "  \n",
        "  # inp -> english, tar -> tamil\n",
        "  for (batch, (inp, tar)) in enumerate(train_dataset):\n",
        "    train_step(inp, tar)\n",
        "    \n",
        "\n",
        "    if batch % 50 == 0:\n",
        "      print ('Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}'.format(\n",
        "          epoch + 1, batch, train_loss.result(), train_accuracy.result()))\n",
        "    # save every 1000 batch\n",
        "    if batch % 1000 == 0:\n",
        "      ckpt_save_path = ckpt_manager.save()\n",
        "      \n",
        "      print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n",
        "                                                            ckpt_save_path))\n",
        "      \n",
        "\n",
        "  print ('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1, \n",
        "                                                train_loss.result(), \n",
        "                                                train_accuracy.result()))\n",
        "  print ('Time taken for {} epoch : {} secs\\n'.format(epoch + 1, time.time() - start))\n",
        "  print('predicted translation {}'.format(tokenizer_ta.decode([j for j in bs('hello')[0][0][0] if j < tokenizer_ta.vocab_size])))\n",
        "  ckpt_save_path = ckpt_manager.save()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 0.4291 Accuracy 0.1569\n",
            "Saving checkpoint for epoch 1 at ./Checkpoints/Train_from_scratch/ckpt-4\n",
            "Epoch 1 Batch 50 Loss 0.5097 Accuracy 0.1593\n",
            "Epoch 1 Batch 100 Loss 0.5027 Accuracy 0.1570\n",
            "Epoch 1 Batch 150 Loss 0.4975 Accuracy 0.1555\n",
            "Epoch 1 Batch 200 Loss 0.4973 Accuracy 0.1557\n",
            "Epoch 1 Batch 250 Loss 0.4949 Accuracy 0.1555\n",
            "Epoch 1 Batch 300 Loss 0.4952 Accuracy 0.1555\n",
            "Epoch 1 Batch 350 Loss 0.4941 Accuracy 0.1554\n",
            "Epoch 1 Batch 400 Loss 0.4928 Accuracy 0.1555\n",
            "Epoch 1 Batch 450 Loss 0.4914 Accuracy 0.1554\n",
            "Epoch 1 Batch 500 Loss 0.4911 Accuracy 0.1554\n",
            "Epoch 1 Batch 550 Loss 0.4908 Accuracy 0.1550\n",
            "Epoch 1 Batch 600 Loss 0.4905 Accuracy 0.1547\n",
            "Epoch 1 Batch 650 Loss 0.4911 Accuracy 0.1546\n",
            "Epoch 1 Batch 700 Loss 0.4928 Accuracy 0.1551\n",
            "Epoch 1 Batch 750 Loss 0.4929 Accuracy 0.1552\n",
            "Epoch 1 Batch 800 Loss 0.4930 Accuracy 0.1550\n",
            "Epoch 1 Batch 850 Loss 0.4930 Accuracy 0.1551\n",
            "Epoch 1 Batch 900 Loss 0.4931 Accuracy 0.1552\n",
            "Epoch 1 Batch 950 Loss 0.4937 Accuracy 0.1553\n",
            "Epoch 1 Batch 1000 Loss 0.4933 Accuracy 0.1552\n",
            "Saving checkpoint for epoch 1 at ./Checkpoints/Train_from_scratch/ckpt-5\n",
            "Epoch 1 Batch 1050 Loss 0.4929 Accuracy 0.1552\n",
            "Epoch 1 Batch 1100 Loss 0.4929 Accuracy 0.1552\n",
            "Epoch 1 Batch 1150 Loss 0.4922 Accuracy 0.1550\n",
            "Epoch 1 Batch 1200 Loss 0.4918 Accuracy 0.1550\n",
            "Epoch 1 Batch 1250 Loss 0.4916 Accuracy 0.1551\n",
            "Epoch 1 Batch 1300 Loss 0.4917 Accuracy 0.1553\n",
            "Epoch 1 Batch 1350 Loss 0.4916 Accuracy 0.1552\n",
            "Epoch 1 Batch 1400 Loss 0.4912 Accuracy 0.1553\n",
            "Epoch 1 Batch 1450 Loss 0.4908 Accuracy 0.1553\n",
            "Epoch 1 Loss 0.4907 Accuracy 0.1554\n",
            "Time taken for 1 epoch : 2148.205892562866 secs\n",
            "\n",
            "predicted translation மாவட்டங்கள்\n",
            "Epoch 2 Batch 0 Loss 0.4228 Accuracy 0.1514\n",
            "Saving checkpoint for epoch 2 at ./Checkpoints/Train_from_scratch/ckpt-7\n",
            "Epoch 2 Batch 50 Loss 0.4900 Accuracy 0.1639\n",
            "Epoch 2 Batch 100 Loss 0.4833 Accuracy 0.1614\n",
            "Epoch 2 Batch 150 Loss 0.4793 Accuracy 0.1599\n",
            "Epoch 2 Batch 200 Loss 0.4790 Accuracy 0.1600\n",
            "Epoch 2 Batch 250 Loss 0.4770 Accuracy 0.1597\n",
            "Epoch 2 Batch 300 Loss 0.4776 Accuracy 0.1596\n",
            "Epoch 2 Batch 350 Loss 0.4764 Accuracy 0.1596\n",
            "Epoch 2 Batch 400 Loss 0.4755 Accuracy 0.1595\n",
            "Epoch 2 Batch 450 Loss 0.4743 Accuracy 0.1594\n",
            "Epoch 2 Batch 500 Loss 0.4736 Accuracy 0.1592\n",
            "Epoch 2 Batch 550 Loss 0.4728 Accuracy 0.1589\n",
            "Epoch 2 Batch 600 Loss 0.4719 Accuracy 0.1587\n",
            "Epoch 2 Batch 650 Loss 0.4720 Accuracy 0.1587\n",
            "Epoch 2 Batch 700 Loss 0.4732 Accuracy 0.1593\n",
            "Epoch 2 Batch 750 Loss 0.4732 Accuracy 0.1593\n",
            "Epoch 2 Batch 800 Loss 0.4730 Accuracy 0.1593\n",
            "Epoch 2 Batch 850 Loss 0.4728 Accuracy 0.1593\n",
            "Epoch 2 Batch 900 Loss 0.4727 Accuracy 0.1594\n",
            "Epoch 2 Batch 950 Loss 0.4731 Accuracy 0.1596\n",
            "Epoch 2 Batch 1000 Loss 0.4726 Accuracy 0.1595\n",
            "Saving checkpoint for epoch 2 at ./Checkpoints/Train_from_scratch/ckpt-8\n",
            "Epoch 2 Batch 1050 Loss 0.4720 Accuracy 0.1594\n",
            "Epoch 2 Batch 1100 Loss 0.4719 Accuracy 0.1595\n",
            "Epoch 2 Batch 1150 Loss 0.4710 Accuracy 0.1594\n",
            "Epoch 2 Batch 1200 Loss 0.4707 Accuracy 0.1594\n",
            "Epoch 2 Batch 1250 Loss 0.4706 Accuracy 0.1595\n",
            "Epoch 2 Batch 1300 Loss 0.4707 Accuracy 0.1596\n",
            "Epoch 2 Batch 1350 Loss 0.4706 Accuracy 0.1595\n",
            "Epoch 2 Batch 1400 Loss 0.4702 Accuracy 0.1596\n",
            "Epoch 2 Batch 1450 Loss 0.4698 Accuracy 0.1596\n",
            "Epoch 2 Loss 0.4696 Accuracy 0.1596\n",
            "Time taken for 2 epoch : 2090.100661277771 secs\n",
            "\n",
            "predicted translation குடும்பம்\n",
            "Epoch 3 Batch 0 Loss 0.4117 Accuracy 0.1657\n",
            "Saving checkpoint for epoch 3 at ./Checkpoints/Train_from_scratch/ckpt-10\n",
            "Epoch 3 Batch 50 Loss 0.4723 Accuracy 0.1672\n",
            "Epoch 3 Batch 100 Loss 0.4652 Accuracy 0.1652\n",
            "Epoch 3 Batch 150 Loss 0.4612 Accuracy 0.1634\n",
            "Epoch 3 Batch 200 Loss 0.4611 Accuracy 0.1637\n",
            "Epoch 3 Batch 250 Loss 0.4590 Accuracy 0.1634\n",
            "Epoch 3 Batch 300 Loss 0.4590 Accuracy 0.1634\n",
            "Epoch 3 Batch 350 Loss 0.4580 Accuracy 0.1633\n",
            "Epoch 3 Batch 400 Loss 0.4570 Accuracy 0.1633\n",
            "Epoch 3 Batch 450 Loss 0.4560 Accuracy 0.1632\n",
            "Epoch 3 Batch 500 Loss 0.4555 Accuracy 0.1631\n",
            "Epoch 3 Batch 550 Loss 0.4545 Accuracy 0.1627\n",
            "Epoch 3 Batch 600 Loss 0.4536 Accuracy 0.1625\n",
            "Epoch 3 Batch 700 Loss 0.4547 Accuracy 0.1632\n",
            "Epoch 3 Batch 750 Loss 0.4546 Accuracy 0.1631\n",
            "Epoch 3 Batch 800 Loss 0.4546 Accuracy 0.1630\n",
            "Epoch 3 Batch 850 Loss 0.4543 Accuracy 0.1631\n",
            "Epoch 3 Batch 900 Loss 0.4543 Accuracy 0.1632\n",
            "Epoch 3 Batch 950 Loss 0.4547 Accuracy 0.1634\n",
            "Epoch 3 Batch 1000 Loss 0.4543 Accuracy 0.1633\n",
            "Saving checkpoint for epoch 3 at ./Checkpoints/Train_from_scratch/ckpt-11\n",
            "Epoch 3 Batch 1050 Loss 0.4537 Accuracy 0.1632\n",
            "Epoch 3 Batch 1100 Loss 0.4536 Accuracy 0.1633\n",
            "Epoch 3 Batch 1150 Loss 0.4528 Accuracy 0.1631\n",
            "Epoch 3 Batch 1200 Loss 0.4525 Accuracy 0.1631\n",
            "Epoch 3 Batch 1250 Loss 0.4523 Accuracy 0.1632\n",
            "Epoch 3 Batch 1300 Loss 0.4525 Accuracy 0.1633\n",
            "Epoch 3 Batch 1350 Loss 0.4525 Accuracy 0.1633\n",
            "Epoch 3 Batch 1400 Loss 0.4521 Accuracy 0.1633\n",
            "Epoch 3 Batch 1450 Loss 0.4518 Accuracy 0.1633\n",
            "Epoch 3 Loss 0.4517 Accuracy 0.1633\n",
            "Time taken for 3 epoch : 2169.397041082382 secs\n",
            "\n",
            "predicted translation திருவாரூர்\n",
            "Epoch 4 Batch 0 Loss 0.3921 Accuracy 0.1585\n",
            "Saving checkpoint for epoch 4 at ./Checkpoints/Train_from_scratch/ckpt-13\n",
            "Epoch 4 Batch 50 Loss 0.4544 Accuracy 0.1718\n",
            "Epoch 4 Batch 100 Loss 0.4488 Accuracy 0.1685\n",
            "Epoch 4 Batch 150 Loss 0.4444 Accuracy 0.1670\n",
            "Epoch 4 Batch 200 Loss 0.4442 Accuracy 0.1673\n",
            "Epoch 4 Batch 250 Loss 0.4430 Accuracy 0.1670\n",
            "Epoch 4 Batch 300 Loss 0.4433 Accuracy 0.1669\n",
            "Epoch 4 Batch 350 Loss 0.4422 Accuracy 0.1668\n",
            "Epoch 4 Batch 400 Loss 0.4415 Accuracy 0.1667\n",
            "Epoch 4 Batch 450 Loss 0.4405 Accuracy 0.1665\n",
            "Epoch 4 Batch 500 Loss 0.4399 Accuracy 0.1664\n",
            "Epoch 4 Batch 550 Loss 0.4390 Accuracy 0.1661\n",
            "Epoch 4 Batch 600 Loss 0.4381 Accuracy 0.1658\n",
            "Epoch 4 Batch 650 Loss 0.4383 Accuracy 0.1659\n",
            "Epoch 4 Batch 700 Loss 0.4394 Accuracy 0.1665\n",
            "Epoch 4 Batch 750 Loss 0.4393 Accuracy 0.1665\n",
            "Epoch 4 Batch 800 Loss 0.4391 Accuracy 0.1664\n",
            "Epoch 4 Batch 850 Loss 0.4389 Accuracy 0.1664\n",
            "Epoch 4 Batch 900 Loss 0.4388 Accuracy 0.1665\n",
            "Epoch 4 Batch 950 Loss 0.4392 Accuracy 0.1667\n",
            "Epoch 4 Batch 1000 Loss 0.4389 Accuracy 0.1665\n",
            "Saving checkpoint for epoch 4 at ./Checkpoints/Train_from_scratch/ckpt-14\n",
            "Epoch 4 Batch 1050 Loss 0.4384 Accuracy 0.1664\n",
            "Epoch 4 Batch 1100 Loss 0.4383 Accuracy 0.1665\n",
            "Epoch 4 Batch 1150 Loss 0.4375 Accuracy 0.1663\n",
            "Epoch 4 Batch 1200 Loss 0.4371 Accuracy 0.1664\n",
            "Epoch 4 Batch 1250 Loss 0.4370 Accuracy 0.1664\n",
            "Epoch 4 Batch 1300 Loss 0.4372 Accuracy 0.1665\n",
            "Epoch 4 Batch 1350 Loss 0.4372 Accuracy 0.1665\n",
            "Epoch 4 Batch 1400 Loss 0.4369 Accuracy 0.1665\n",
            "Epoch 4 Batch 1450 Loss 0.4366 Accuracy 0.1665\n",
            "Epoch 4 Loss 0.4365 Accuracy 0.1665\n",
            "Time taken for 4 epoch : 2077.3934140205383 secs\n",
            "\n",
            "predicted translation திருப்பூர்\n",
            "Epoch 5 Batch 0 Loss 0.3730 Accuracy 0.1641\n",
            "Saving checkpoint for epoch 5 at ./Checkpoints/Train_from_scratch/ckpt-16\n",
            "Epoch 5 Batch 50 Loss 0.4402 Accuracy 0.1745\n",
            "Epoch 5 Batch 100 Loss 0.4340 Accuracy 0.1715\n",
            "Epoch 5 Batch 150 Loss 0.4294 Accuracy 0.1700\n",
            "Epoch 5 Batch 200 Loss 0.4293 Accuracy 0.1703\n",
            "Epoch 5 Batch 250 Loss 0.4281 Accuracy 0.1700\n",
            "Epoch 5 Batch 300 Loss 0.4283 Accuracy 0.1700\n",
            "Epoch 5 Batch 350 Loss 0.4275 Accuracy 0.1699\n",
            "Epoch 5 Batch 400 Loss 0.4268 Accuracy 0.1698\n",
            "Epoch 5 Batch 450 Loss 0.4260 Accuracy 0.1696\n",
            "Epoch 5 Batch 500 Loss 0.4255 Accuracy 0.1695\n",
            "Epoch 5 Batch 550 Loss 0.4246 Accuracy 0.1692\n",
            "Epoch 5 Batch 600 Loss 0.4239 Accuracy 0.1689\n",
            "Epoch 5 Batch 650 Loss 0.4243 Accuracy 0.1689\n",
            "Epoch 5 Batch 700 Loss 0.4255 Accuracy 0.1695\n",
            "Epoch 5 Batch 750 Loss 0.4253 Accuracy 0.1695\n",
            "Epoch 5 Batch 800 Loss 0.4252 Accuracy 0.1694\n",
            "Epoch 5 Batch 850 Loss 0.4250 Accuracy 0.1694\n",
            "Epoch 5 Batch 900 Loss 0.4250 Accuracy 0.1695\n",
            "Epoch 5 Batch 950 Loss 0.4254 Accuracy 0.1696\n",
            "Epoch 5 Batch 1000 Loss 0.4251 Accuracy 0.1695\n",
            "Saving checkpoint for epoch 5 at ./Checkpoints/Train_from_scratch/ckpt-17\n",
            "Epoch 5 Batch 1050 Loss 0.4246 Accuracy 0.1695\n",
            "Epoch 5 Batch 1100 Loss 0.4246 Accuracy 0.1695\n",
            "Epoch 5 Batch 1150 Loss 0.4239 Accuracy 0.1693\n",
            "Epoch 5 Batch 1200 Loss 0.4237 Accuracy 0.1693\n",
            "Epoch 5 Batch 1250 Loss 0.4236 Accuracy 0.1694\n",
            "Epoch 5 Batch 1300 Loss 0.4237 Accuracy 0.1695\n",
            "Epoch 5 Batch 1350 Loss 0.4236 Accuracy 0.1694\n",
            "Epoch 5 Batch 1400 Loss 0.4233 Accuracy 0.1695\n",
            "Epoch 5 Batch 1450 Loss 0.4231 Accuracy 0.1694\n",
            "Epoch 5 Loss 0.4230 Accuracy 0.1695\n",
            "Time taken for 5 epoch : 2123.645046234131 secs\n",
            "\n",
            "predicted translation பாரதியார்\n",
            "Epoch 6 Batch 0 Loss 0.3656 Accuracy 0.1729\n",
            "Saving checkpoint for epoch 6 at ./Checkpoints/Train_from_scratch/ckpt-19\n",
            "Epoch 6 Batch 50 Loss 0.4278 Accuracy 0.1771\n",
            "Epoch 6 Batch 100 Loss 0.4221 Accuracy 0.1742\n",
            "Epoch 6 Batch 150 Loss 0.4181 Accuracy 0.1724\n",
            "Epoch 6 Batch 200 Loss 0.4175 Accuracy 0.1729\n",
            "Epoch 6 Batch 250 Loss 0.4162 Accuracy 0.1725\n",
            "Epoch 6 Batch 300 Loss 0.4164 Accuracy 0.1725\n",
            "Epoch 6 Batch 350 Loss 0.4156 Accuracy 0.1724\n",
            "Epoch 6 Batch 400 Loss 0.4149 Accuracy 0.1723\n",
            "Epoch 6 Batch 450 Loss 0.4141 Accuracy 0.1722\n",
            "Epoch 6 Batch 500 Loss 0.4136 Accuracy 0.1721\n",
            "Epoch 6 Batch 550 Loss 0.4126 Accuracy 0.1718\n",
            "Epoch 6 Batch 600 Loss 0.4119 Accuracy 0.1715\n",
            "Epoch 6 Batch 650 Loss 0.4121 Accuracy 0.1715\n",
            "Epoch 6 Batch 700 Loss 0.4133 Accuracy 0.1721\n",
            "Epoch 6 Batch 750 Loss 0.4133 Accuracy 0.1721\n",
            "Epoch 6 Batch 800 Loss 0.4132 Accuracy 0.1720\n",
            "Epoch 6 Batch 850 Loss 0.4131 Accuracy 0.1720\n",
            "Epoch 6 Batch 900 Loss 0.4130 Accuracy 0.1721\n",
            "Epoch 6 Batch 950 Loss 0.4134 Accuracy 0.1722\n",
            "Epoch 6 Batch 1000 Loss 0.4131 Accuracy 0.1721\n",
            "Saving checkpoint for epoch 6 at ./Checkpoints/Train_from_scratch/ckpt-20\n",
            "Epoch 6 Batch 1050 Loss 0.4127 Accuracy 0.1720\n",
            "Epoch 6 Batch 1100 Loss 0.4126 Accuracy 0.1721\n",
            "Epoch 6 Batch 1150 Loss 0.4119 Accuracy 0.1719\n",
            "Epoch 6 Batch 1200 Loss 0.4117 Accuracy 0.1719\n",
            "Epoch 6 Batch 1250 Loss 0.4116 Accuracy 0.1720\n",
            "Epoch 6 Batch 1300 Loss 0.4118 Accuracy 0.1720\n",
            "Epoch 6 Batch 1350 Loss 0.4118 Accuracy 0.1720\n",
            "Epoch 6 Batch 1400 Loss 0.4115 Accuracy 0.1720\n",
            "Epoch 6 Batch 1450 Loss 0.4113 Accuracy 0.1720\n",
            "Epoch 6 Loss 0.4112 Accuracy 0.1720\n",
            "Time taken for 6 epoch : 2073.732100725174 secs\n",
            "\n",
            "predicted translation பாரதியார் பாடல்\n",
            "Epoch 7 Batch 0 Loss 0.3613 Accuracy 0.1673\n",
            "Saving checkpoint for epoch 7 at ./Checkpoints/Train_from_scratch/ckpt-22\n",
            "Epoch 7 Batch 50 Loss 0.4162 Accuracy 0.1790\n",
            "Epoch 7 Batch 100 Loss 0.4119 Accuracy 0.1762\n",
            "Epoch 7 Batch 150 Loss 0.4080 Accuracy 0.1745\n",
            "Epoch 7 Batch 200 Loss 0.4075 Accuracy 0.1749\n",
            "Epoch 7 Batch 250 Loss 0.4059 Accuracy 0.1747\n",
            "Epoch 7 Batch 300 Loss 0.4058 Accuracy 0.1747\n",
            "Epoch 7 Batch 350 Loss 0.4049 Accuracy 0.1746\n",
            "Epoch 7 Batch 400 Loss 0.4044 Accuracy 0.1744\n",
            "Epoch 7 Batch 450 Loss 0.4037 Accuracy 0.1742\n",
            "Epoch 7 Batch 500 Loss 0.4033 Accuracy 0.1741\n",
            "Epoch 7 Batch 550 Loss 0.4025 Accuracy 0.1738\n",
            "Epoch 7 Batch 600 Loss 0.4018 Accuracy 0.1735\n",
            "Epoch 7 Batch 650 Loss 0.4020 Accuracy 0.1735\n",
            "Epoch 7 Batch 700 Loss 0.4032 Accuracy 0.1741\n",
            "Epoch 7 Batch 750 Loss 0.4032 Accuracy 0.1741\n",
            "Epoch 7 Batch 800 Loss 0.4031 Accuracy 0.1740\n",
            "Epoch 7 Batch 850 Loss 0.4029 Accuracy 0.1740\n",
            "Epoch 7 Batch 900 Loss 0.4028 Accuracy 0.1741\n",
            "Epoch 7 Batch 950 Loss 0.4031 Accuracy 0.1743\n",
            "Epoch 7 Batch 1000 Loss 0.4028 Accuracy 0.1742\n",
            "Saving checkpoint for epoch 7 at ./Checkpoints/Train_from_scratch/ckpt-23\n",
            "Epoch 7 Batch 1050 Loss 0.4024 Accuracy 0.1741\n",
            "Epoch 7 Batch 1100 Loss 0.4023 Accuracy 0.1742\n",
            "Epoch 7 Batch 1150 Loss 0.4017 Accuracy 0.1740\n",
            "Epoch 7 Batch 1200 Loss 0.4015 Accuracy 0.1740\n",
            "Epoch 7 Batch 1250 Loss 0.4014 Accuracy 0.1740\n",
            "Epoch 7 Batch 1300 Loss 0.4016 Accuracy 0.1742\n",
            "Epoch 7 Batch 1350 Loss 0.4016 Accuracy 0.1741\n",
            "Epoch 7 Batch 1400 Loss 0.4013 Accuracy 0.1742\n",
            "Epoch 7 Batch 1450 Loss 0.4011 Accuracy 0.1741\n",
            "Epoch 7 Loss 0.4011 Accuracy 0.1741\n",
            "Time taken for 7 epoch : 2058.7816166877747 secs\n",
            "\n",
            "predicted translation திருநெல்வேலி மக்களவைத் தொகுதி\n",
            "Epoch 8 Batch 0 Loss 0.3575 Accuracy 0.1683\n",
            "Saving checkpoint for epoch 8 at ./Checkpoints/Train_from_scratch/ckpt-25\n",
            "Epoch 8 Batch 50 Loss 0.4068 Accuracy 0.1816\n",
            "Epoch 8 Batch 100 Loss 0.4010 Accuracy 0.1786\n",
            "Epoch 8 Batch 150 Loss 0.3976 Accuracy 0.1769\n",
            "Epoch 8 Batch 200 Loss 0.3974 Accuracy 0.1771\n",
            "Epoch 8 Batch 250 Loss 0.3963 Accuracy 0.1769\n",
            "Epoch 8 Batch 300 Loss 0.3966 Accuracy 0.1767\n",
            "Epoch 8 Batch 350 Loss 0.3957 Accuracy 0.1767\n",
            "Epoch 8 Batch 400 Loss 0.3948 Accuracy 0.1767\n",
            "Epoch 8 Batch 450 Loss 0.3941 Accuracy 0.1765\n",
            "Epoch 8 Batch 500 Loss 0.3936 Accuracy 0.1764\n",
            "Epoch 8 Batch 550 Loss 0.3929 Accuracy 0.1761\n",
            "Epoch 8 Batch 600 Loss 0.3923 Accuracy 0.1758\n",
            "Epoch 8 Batch 650 Loss 0.3924 Accuracy 0.1758\n",
            "Epoch 8 Batch 700 Loss 0.3935 Accuracy 0.1764\n",
            "Epoch 8 Batch 750 Loss 0.3934 Accuracy 0.1765\n",
            "Epoch 8 Batch 800 Loss 0.3933 Accuracy 0.1763\n",
            "Epoch 8 Batch 850 Loss 0.3933 Accuracy 0.1763\n",
            "Epoch 8 Batch 900 Loss 0.3932 Accuracy 0.1764\n",
            "Epoch 8 Batch 950 Loss 0.3936 Accuracy 0.1766\n",
            "Epoch 8 Batch 1000 Loss 0.3933 Accuracy 0.1765\n",
            "Saving checkpoint for epoch 8 at ./Checkpoints/Train_from_scratch/ckpt-26\n",
            "Epoch 8 Batch 1050 Loss 0.3930 Accuracy 0.1764\n",
            "Epoch 8 Batch 1100 Loss 0.3929 Accuracy 0.1764\n",
            "Epoch 8 Batch 1150 Loss 0.3923 Accuracy 0.1762\n",
            "Epoch 8 Batch 1200 Loss 0.3921 Accuracy 0.1762\n",
            "Epoch 8 Batch 1250 Loss 0.3920 Accuracy 0.1763\n",
            "Epoch 8 Batch 1300 Loss 0.3921 Accuracy 0.1764\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Ow5v0Mp9iFO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# beam search with beam size 3\n",
        "\n",
        "def bs(inp_sentence):\n",
        "  inp_sentence = inp_sentence\n",
        "  beam_size = 4\n",
        "  start_token = [tokenizer_en.vocab_size]\n",
        "  end_token = [tokenizer_en.vocab_size + 1]\n",
        "  inp_sentence = start_token + tokenizer_en.encode(inp_sentence) + end_token\n",
        "  encoder_input = tf.expand_dims(inp_sentence, 0)\n",
        "  encoder_input = tf.concat([encoder_input]*beam_size, axis=0)\n",
        "  start = tokenizer_ta.vocab_size\n",
        "  end = tokenizer_ta.vocab_size+1\n",
        "  def transformer_query(output):\n",
        "\n",
        "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
        "          encoder_input, output)\n",
        "    predictions, attention_weights = transformer(encoder_input, \n",
        "                                                 output,\n",
        "                                                 False,\n",
        "                                                 enc_padding_mask,\n",
        "                                                 combined_mask,\n",
        "                                                 dec_padding_mask)\n",
        "\n",
        "\n",
        "    return (predictions[:,-1:,:])\n",
        "  return beam_search(transformer_query, [start], beam_size, 30, target_vocab_size, 1, stop_early=True, eos_id=[tokenizer_ta.vocab_size+1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d453r8nvLnvy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "start = time.time()\n",
        "text = input('Enter a english sentence:- ')\n",
        "translated_output = bs(text)[0][0]\n",
        "print('probable outputs')\n",
        "for dec_ids in translated_output:\n",
        "  print(tokenizer_ta.decode([j for j in dec_ids if j < tokenizer_ta.vocab_size]))\n",
        "\n",
        "print('time to process {}'.format(time.time()-start))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sziqNpRh7t7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Add more data\n",
        "#https://github.com/praveenjune17/Neural-Machine-Translation-English-Tamil-model/blob/master/tfds_patch_scripts/Transformer_en_tam_2.zip\n",
        "\n",
        "\n",
        "# The dataset used here contains 100K lines (even lesser after applying filter_max_length) so with more data the translation\n",
        "  #quality will be better. Have trained a model with 450Klines of parallel text , data were downloaded from the below links\n",
        " \n",
        "  #If you are willing to contribute additional data that is not in\n",
        "  #https://github.com/praveenjune17/English_Tamil_parallel_corpus/blob/master/Available_download_links then Please add.\n",
        "  \n",
        "  \n",
        "# increase MAX_LENGTH to 100 or 120 to train long sentences but make sure the training  is carried out on high end GPUs.\n",
        "  # In Colab GPU crashes when MAX_LENGTH > 51\n",
        "\n",
        "# train tamil to english model\n",
        "  \n",
        "# Please refer to https://github.com/praveenjune17/datasets/blob/master/tensorflow_datasets/translate/en_tam_parallel_text.py\n",
        "  # for the preprocessing steps carried out.Open for suggestions"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}